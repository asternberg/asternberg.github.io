# asternberg.github.io

#Date April 7, 2025


#Date: March 9, 2025
for comparison - this is what gpt4.5 says about my backyard with a low quality image and about about 2sec processing time. This is so much better - and I don't have to rely on classifications/multiple passes. Can't wait to have this level of a multimodal LLM running locally. 

#​Date: March 7, 2025​

I've connected my Home-Assistant cameras to CV classifications and an LLM. Now, I can simply ask, "Is there anyone outside?" and receive a natural language response based on the live feeds. This setup doesn't store any data or communicate outside my network. I ran it with a local LLM on a Mac mini and achieved good results. Check out the project here: . Open source (MIT License). It took me ~6 hours to put everything together, without being a TypeScript/NodeJS expert. The age of AI code assistants is wonderful. And no, there are no trains in my backyard. Thank you YOLOv8 (the classification model).

![Alt text describing the image](imgs/ha_screenshot1.jpg)